{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7 - Support Vector Machines (SVMs)\n",
    "\n",
    "(20 points)\n",
    "\n",
    "### Add your name(s) and EIDs below\n",
    "- Student Name: Siem Yonas\n",
    "- Student UT EID: sby237\n",
    "- Partner Name:\n",
    "- Partner UT EID:\n",
    "\n",
    "### Grading clarifications\n",
    "1. Before you submit:\n",
    "    - **Please do not change or remove any variable names** we give you for your answer to each question. You can use other variables if you wish, but the final answer must be stored in that variable.\n",
    "    - **Please don't use any other libraries** besides those provided in `requirements.txt`, and those [built in to Python](https://docs.python.org/3.8/library/index.html).\n",
    "2. We will also be double-checking the autograder, so you won't lose points if your formatting causes it to deduct points (but please try to follow the points under 1).\n",
    "3. After submitting, you may see \"All test cases passed!\" for Public Tests. Please note that this doesn't mean you have correctly answered every question, as there are no public tests. We will be using a series of hidden tests to verify your answers are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Headers\n",
    "# You are welcome to add additional headers here if you wish\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable inline mode for matplotlib so that Jupyter displays graphs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Dataset \n",
    "\n",
    "In this Assignment we will work with some patients dataset. \n",
    "\n",
    "We have access to 303 patients data. The features are listed below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  ExAng  \\\n",
       "0     63    1       typical     145   233    1        2    150      0   \n",
       "1     67    1  asymptomatic     160   286    0        2    108      1   \n",
       "2     67    1  asymptomatic     120   229    0        2    129      1   \n",
       "3     37    1    nonanginal     130   250    0        0    187      0   \n",
       "4     41    0    nontypical     130   204    0        2    172      0   \n",
       "..   ...  ...           ...     ...   ...  ...      ...    ...    ...   \n",
       "298   45    1       typical     110   264    0        0    132      0   \n",
       "299   68    1  asymptomatic     144   193    1        0    141      0   \n",
       "300   57    1  asymptomatic     130   131    0        0    115      1   \n",
       "301   57    0    nontypical     130   236    0        2    174      0   \n",
       "302   38    1    nonanginal     138   175    0        0    173      0   \n",
       "\n",
       "     Oldpeak  Slope   Ca        Thal Target  \n",
       "0        2.3      3  0.0       fixed     No  \n",
       "1        1.5      2  3.0      normal    Yes  \n",
       "2        2.6      2  2.0  reversable    Yes  \n",
       "3        3.5      3  0.0      normal     No  \n",
       "4        1.4      1  0.0      normal     No  \n",
       "..       ...    ...  ...         ...    ...  \n",
       "298      1.2      2  0.0  reversable    Yes  \n",
       "299      3.4      2  2.0  reversable    Yes  \n",
       "300      1.2      2  1.0  reversable    Yes  \n",
       "301      0.0      2  1.0      normal    Yes  \n",
       "302      0.0      1  NaN      normal     No  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "heart_df = pd.read_csv(\"Heart.csv\")\n",
    "heart_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age:** The personâ€™s age in years\n",
    "\n",
    "**Sex:** The personâ€™s sex (1 = male, 0 = female)\n",
    "\n",
    "**ChestPain:** chest pain type\n",
    "* Value 0: asymptomatic\n",
    "* Value 1: atypical angina\n",
    "* Value 2: non-anginal pain\n",
    "* Value 3: typical angina\n",
    "\n",
    "**RestBP:** The personâ€™s resting blood pressure (mm Hg on admission to the hospital)\n",
    "\n",
    "**Chol:** The personâ€™s cholesterol measurement in mg/dl\n",
    "\n",
    "**Fbs:** The personâ€™s fasting blood sugar (> 120 mg/dl, 1 = true; 0 = false)\n",
    "\n",
    "**RestECG**: resting electrocardiographic results\n",
    "* Value 0: showing probable or definite left ventricular hypertrophy by Estesâ€™ criteria\n",
    "* Value 1: normal\n",
    "* Value 2: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "\n",
    "**MaxHR:** The personâ€™s maximum heart rate achieved\n",
    "\n",
    "**ExAng:** Exercise induced angina (1 = yes; 0 = no)\n",
    "\n",
    "**Oldpeak:** ST depression induced by exercise relative to rest (â€˜STâ€™ relates to positions on the ECG plot.)\n",
    "\n",
    "**Slope:** the slope of the peak exercise ST segment\n",
    "* 0: downsloping; \n",
    "* 1: flat; \n",
    "* 2: upsloping\n",
    "\n",
    "**Ca:** The number of major vessels (0â€“3)\n",
    "\n",
    "**Thal:** A blood disorder called thalassemia \n",
    "* Value 0: NULL (dropped from the dataset previously\n",
    "* Value 1: fixed defect (no blood flow in some part of the heart)\n",
    "* Value 2: normal blood flow\n",
    "* Value 3: reversible defect (a blood flow is observed but it is not normal)\n",
    "\n",
    "**Target:** Heart disease (1 = yes; 0 = no)\n",
    "- **Note**: For Q1, Q4, and Q5. your labels can be arbitrary. But, for Q3, you will need to ensure that \"Yes\" = 1 and \"No\" = -1, as an SVM predicts 1 and -1, not 1 and 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 \n",
    "\n",
    "**Implement SVM using libraries**: We want to use a **support vector machine** to predict if each patient will have heart problems or not. The column \"Target\" in our datasets includes data about heart diseases. If the patient had heart disease, it is labeled \"Yes\", otherwise it is labeled \"No\".\n",
    "\n",
    "As you did in Assignment 5, please prepare your dataset for predicting heart disease (\"Target\" column) by using 3 features:\n",
    "\n",
    "- Age of the patient (Column **\"Age\"**)\n",
    "- Gender of the patient (male or female - Column **\"Sex\"**)\n",
    "- Cholestrol level of the patient (Column **\"Chol\"**) \n",
    "\n",
    "\n",
    "Split your data into 80% traning data and 20% test data.\n",
    "\n",
    "Finally, implement a Support Vector Machine using Scikit-Learn and train it on your training set. (**4 points**)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Put the features into an \"X\" array, and target variable into a \"y\" array.\n",
    "X = heart_df[[\"Age\", \"Sex\", \"Chol\"]]\n",
    "y = heart_df[\"Target\"].map({'Yes':1, 'No':-1})\n",
    "\n",
    "# Normalize input features\n",
    "X = (X - X.mean())/X.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Age       Sex      Chol\n",
      "102  0.283345 -1.454889  1.087491\n",
      "261  0.393980 -1.454889  1.396509\n",
      "228 -0.048563  0.685069 -0.785931\n",
      "288  0.172709  0.685069 -0.496226\n",
      "78  -0.712378  0.685069 -0.032699\n",
      "..        ...       ...       ...\n",
      "106  0.504616  0.685069 -1.346026\n",
      "83   1.500339  0.685069  0.527396\n",
      "17  -0.048563  0.685069 -0.148581\n",
      "230 -0.269835 -1.454889 -0.979067\n",
      "98  -0.269835  0.685069 -0.882499\n",
      "\n",
      "[242 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Split your \"X\" and \"y\" arrays into training and testing sets. \n",
    "# You may use scikit-learn to do this.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Create an SVM using SciKit-Learn, and train it on your training set.\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Q2\n",
    "\n",
    "Calculate the accuracy, Precision, recall and F1 score of your **SVM** implementaion from Task 1 on the testing dataset. \n",
    "Print the results. You may use library methods for this task if you choose to. (**4 points**)\n",
    "\n",
    "(This question will be manually graded.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.76      0.75        33\n",
      "           1       0.70      0.68      0.69        28\n",
      "\n",
      "    accuracy                           0.72        61\n",
      "   macro avg       0.72      0.72      0.72        61\n",
      "weighted avg       0.72      0.72      0.72        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Q3 \n",
    "\n",
    "**Implement SVM without using libraries**: Implement a SVM from scratch using the hinge loss \n",
    "function and gradient descent. Try to replicate the same results as you got from the scikit-learn\n",
    "SVM. Report the accuracy, precision, recall, and F1-score of your model.\n",
    "\n",
    "- You can re-use your training/testing set from Q1, but you may need to rename your target variable (e.g. \"No\", \"Yes\") to a number. If so,\n",
    "  assign 1 to \"Yes\"es and -1 to \"No\"s. (**Note: setting \"No\"s to -1 is very important here!**)\n",
    "- Do as many iterations as needed, with a maximum of **100 iterations**.\n",
    "- Use a very small learning rate for checking your GD implementation. \n",
    "- You are allowed to use your choice of learning rate, like using 0.0001, 0.001 or 0.01 or 0.1 or higher. \n",
    "- Visualize your costs with a plot (similar to Assignments 5 and 6). \n",
    "- No need to add an y-intercept in this task.\n",
    "- You can use libraries to report the accuracy, precision, recall and F1-score. \n",
    "\n",
    "(**4 points - 2 for code, 1 for metrics, 1 for visualization**)\n",
    "\n",
    "**Hint**: Here are the formulae for hinge loss and its gradient:\n",
    "\n",
    "Hinge loss function (with regularization):\n",
    "$$ \n",
    "cost = \\frac{ \\lambda }{ 2 } ||w||^2 + \\frac{1}{N} \\sum_i^n max(0, 1 - y_i (w \\cdot x_i))\n",
    "$$\n",
    "- $x_i$: Training sample $x_i$\n",
    "- $y_i$: Training label $y_i$\n",
    "- $w$: SVM weights\n",
    "- $N$: Number of elements\n",
    "- $\\lambda$: Regularization parameter, $= \\frac{1}{N \\times c}$\n",
    "\n",
    "Gradient of hinge loss:\n",
    "\n",
    "$$gradient(w)=\\frac{1}{N}\\sum_i^n\n",
    "\\begin{cases}\n",
    "w &  \\text{ if } max(0, y_i (w \\cdot x_i)) = 0 \\\\\n",
    "w - c y_i x_i &  \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Implement hinge cost and its gradient function.\n",
    "def hinge_loss(X, y, W, c):\n",
    "    \"\"\"Calculate the hinge loss function, with regularization.\n",
    "    \n",
    "    Parameters:\n",
    "        X: Training set samples\n",
    "        y: Training set labels\n",
    "        W: Current weights of the SVM.\n",
    "        c: The term c in the formula above (used to define lambda)\n",
    "\n",
    "    Returns:\n",
    "        hinge_loss: The hinge loss.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    distances = 1 - y * (np.dot(X, W))\n",
    "    \n",
    "    # This is our max(0, distance). \n",
    "    distances[distances < 0] = 0 \n",
    "    \n",
    "    hinge_loss = c * (np.sum(distances) / n)\n",
    "    # This divide by 2 is not important. You can skip doing it \n",
    "    # because we want only to check if this cost is going down or not. \n",
    "    return (1 / 2 * np.dot(W, W) + hinge_loss)\n",
    "    \n",
    "    hinge_loss = ...\n",
    "    return hinge_loss\n",
    "\n",
    "def hinge_loss_gradient(X, y, W, c):\n",
    "    \"\"\"Calculate the gradient of the hinge loss function.\n",
    "    \n",
    "    Parameters:\n",
    "        X: Training set samples\n",
    "        y: Training set labels\n",
    "        W: Current weights of the SVM.\n",
    "        c: The term c in the formula above (used to define lambda)\n",
    "\n",
    "    Returns:\n",
    "        dW: The gradient of the hinge loss with respect to each feature.\n",
    "    \"\"\"\n",
    "    if type(y) == np.float64:\n",
    "        y = np.array([y])\n",
    "        X = np.array([X])\n",
    "        \n",
    "    if type(y) == pd.Series:\n",
    "        y = y.values\n",
    "        X = X.values\n",
    "        \n",
    "    distance = 1 - (y * np.dot(X, W))\n",
    "    \n",
    "    dw = np.zeros(len(W))\n",
    "    \n",
    "    for ind, d in enumerate(distance):\n",
    "        \n",
    "        if (d < 0):\n",
    "            di = W\n",
    "        else:\n",
    "            di = W - (c * y[ind] * X[ind])\n",
    "            \n",
    "            \n",
    "        dw += di\n",
    "    \n",
    "    dw = dw/len(y)  # average\n",
    "    \n",
    "    return dw\n",
    "\n",
    "def predict_svm(X, W):\n",
    "    \"\"\"Predict the label for a set of samples, given an SVM\n",
    "    with weights W. \n",
    "    \n",
    "    (Hint: You won't need this for your gradient descent, just your\n",
    "     final metrics collection)\n",
    "     \n",
    "    Parameters:\n",
    "        X: Training set samples\n",
    "        W: Current weights of the SVM.\n",
    "        \n",
    "    Returns:\n",
    "        y_pred: Predicted classification of the samples.\n",
    "    \"\"\"\n",
    "    y_pred = np.where(np.dot(X, W)<0, -1, 1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration   1: Cost: 0.0100\n",
      "Iteration   2: Cost: 0.0100\n",
      "Iteration   3: Cost: 0.0100\n",
      "Iteration   4: Cost: 0.0100\n",
      "Iteration   5: Cost: 0.0100\n",
      "Iteration   6: Cost: 0.0100\n",
      "Iteration   7: Cost: 0.0100\n",
      "Iteration   8: Cost: 0.0100\n",
      "Iteration   9: Cost: 0.0100\n",
      "Iteration  10: Cost: 0.0100\n",
      "Iteration  11: Cost: 0.0100\n",
      "Iteration  12: Cost: 0.0100\n",
      "Iteration  13: Cost: 0.0100\n",
      "Iteration  14: Cost: 0.0100\n",
      "Iteration  15: Cost: 0.0100\n",
      "Iteration  16: Cost: 0.0100\n",
      "Iteration  17: Cost: 0.0100\n",
      "Iteration  18: Cost: 0.0100\n",
      "Iteration  19: Cost: 0.0100\n",
      "Iteration  20: Cost: 0.0100\n",
      "Iteration  21: Cost: 0.0100\n",
      "Iteration  22: Cost: 0.0100\n",
      "Iteration  23: Cost: 0.0100\n",
      "Iteration  24: Cost: 0.0100\n",
      "Iteration  25: Cost: 0.0100\n",
      "Iteration  26: Cost: 0.0100\n",
      "Iteration  27: Cost: 0.0100\n",
      "Iteration  28: Cost: 0.0100\n",
      "Iteration  29: Cost: 0.0100\n",
      "Iteration  30: Cost: 0.0100\n",
      "Iteration  31: Cost: 0.0100\n",
      "Iteration  32: Cost: 0.0100\n",
      "Iteration  33: Cost: 0.0100\n",
      "Iteration  34: Cost: 0.0100\n",
      "Iteration  35: Cost: 0.0100\n",
      "Iteration  36: Cost: 0.0100\n",
      "Iteration  37: Cost: 0.0100\n",
      "Iteration  38: Cost: 0.0100\n",
      "Iteration  39: Cost: 0.0100\n",
      "Iteration  40: Cost: 0.0100\n",
      "Iteration  41: Cost: 0.0100\n",
      "Iteration  42: Cost: 0.0100\n",
      "Iteration  43: Cost: 0.0100\n",
      "Iteration  44: Cost: 0.0100\n",
      "Iteration  45: Cost: 0.0100\n",
      "Iteration  46: Cost: 0.0100\n",
      "Iteration  47: Cost: 0.0100\n",
      "Iteration  48: Cost: 0.0100\n",
      "Iteration  49: Cost: 0.0100\n",
      "Iteration  50: Cost: 0.0100\n",
      "Iteration  51: Cost: 0.0100\n",
      "Iteration  52: Cost: 0.0100\n",
      "Iteration  53: Cost: 0.0100\n",
      "Iteration  54: Cost: 0.0100\n",
      "Iteration  55: Cost: 0.0100\n",
      "Iteration  56: Cost: 0.0100\n",
      "Iteration  57: Cost: 0.0100\n",
      "Iteration  58: Cost: 0.0100\n",
      "Iteration  59: Cost: 0.0100\n",
      "Iteration  60: Cost: 0.0100\n",
      "Iteration  61: Cost: 0.0100\n",
      "Iteration  62: Cost: 0.0100\n",
      "Iteration  63: Cost: 0.0100\n",
      "Iteration  64: Cost: 0.0100\n",
      "Iteration  65: Cost: 0.0100\n",
      "Iteration  66: Cost: 0.0100\n",
      "Iteration  67: Cost: 0.0100\n",
      "Iteration  68: Cost: 0.0100\n",
      "Iteration  69: Cost: 0.0100\n",
      "Iteration  70: Cost: 0.0100\n",
      "Iteration  71: Cost: 0.0100\n",
      "Iteration  72: Cost: 0.0100\n",
      "Iteration  73: Cost: 0.0100\n",
      "Iteration  74: Cost: 0.0100\n",
      "Iteration  75: Cost: 0.0100\n",
      "Iteration  76: Cost: 0.0100\n",
      "Iteration  77: Cost: 0.0100\n",
      "Iteration  78: Cost: 0.0100\n",
      "Iteration  79: Cost: 0.0100\n",
      "Iteration  80: Cost: 0.0100\n",
      "Iteration  81: Cost: 0.0100\n",
      "Iteration  82: Cost: 0.0100\n",
      "Iteration  83: Cost: 0.0100\n",
      "Iteration  84: Cost: 0.0100\n",
      "Iteration  85: Cost: 0.0100\n",
      "Iteration  86: Cost: 0.0100\n",
      "Iteration  87: Cost: 0.0100\n",
      "Iteration  88: Cost: 0.0100\n",
      "Iteration  89: Cost: 0.0100\n",
      "Iteration  90: Cost: 0.0100\n",
      "Iteration  91: Cost: 0.0100\n",
      "Iteration  92: Cost: 0.0100\n",
      "Iteration  93: Cost: 0.0100\n",
      "Iteration  94: Cost: 0.0100\n",
      "Iteration  95: Cost: 0.0100\n",
      "Iteration  96: Cost: 0.0100\n",
      "Iteration  97: Cost: 0.0100\n",
      "Iteration  98: Cost: 0.0100\n",
      "Iteration  99: Cost: 0.0100\n",
      "Iteration 100: Cost: 0.0100\n"
     ]
    }
   ],
   "source": [
    "# Implement an iterative SVM trained via gradient descent. \n",
    "# Make sure your y-labels are in the right format (-1 for \"No\", 1 for \"Yes\")\n",
    "weights = np.zeros(X.shape[1])\n",
    "num_iterations = 100\n",
    "lr = 0.1\n",
    "c = 0.01\n",
    "cost_list = []\n",
    "\n",
    "# Implement gradient descent here.\n",
    "for i in range(num_iterations):\n",
    "    cost = hinge_loss(X_train, y_train, weights, c)\n",
    "    cost_list.append(cost)\n",
    "    \n",
    "    grad = hinge_loss_gradient(X_train, y_train, weights, c)\n",
    "    \n",
    "    weights -= lr * grad\n",
    "    \n",
    "    print(f\"Iteration {i+1:3}: Cost: {cost:5.4f}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cost')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize your cost function over each iteration.\n",
    "plt.plot(cost_list)\n",
    "plt.title(\"SVM Gradient Descent\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.55      0.64        33\n",
      "           1       0.61      0.82      0.70        28\n",
      "\n",
      "    accuracy                           0.67        61\n",
      "   macro avg       0.69      0.68      0.67        61\n",
      "weighted avg       0.70      0.67      0.67        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute and print metrics for you SVM on the testing dataset.\n",
    "y_pred = predict_svm(X_test, weights)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Q4\n",
    "\n",
    "**Compare SVM results to logistic regression**: Implement a logistic regression to solve this task, using libraries (like Assignment 5). Compare the performance of the logistic regression model to your SVM models on the testing dataset. You can use metrics like accuracy, precision, recall, the F1-score, and any other metric you think may be useful for this comparison. Which one performs better?\n",
    "\n",
    "**(4 points - 2 for implemenation, 2 for description)**\n",
    "\n",
    "(This question will be manually graded.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two models perform very similiarly. For this random state, precision is better for the SVM, the recall is better for SVM for -1 (No) and better for logistic regression for 1 (Yes), and the f1-score is higher for the SVM. In this random state, the SVM performed slightly better, but since the values are close, it is plausible that another split of the data could produce different results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a logistic regression model.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "\n",
    "# Fit the model to your training data.\n",
    "log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.70      0.72        33\n",
      "           1       0.67      0.71      0.69        28\n",
      "\n",
      "    accuracy                           0.70        61\n",
      "   macro avg       0.70      0.71      0.70        61\n",
      "weighted avg       0.71      0.70      0.71        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze the performance of the logistic regression on the testing dataset.\n",
    "y_pred = log_model.predict(X_test)\n",
    "report = classification_report(y_test,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Q5\n",
    "\n",
    "**Apply a kernel function to your SVM**: Using the Scikit-learn library, revisit the SVM you implemented in Question 1 and experiment with different kernel functions. Can you improve its performance? Describe your results.\n",
    "\n",
    "**(4 points - 2 for implementation, 2 for description)**\n",
    "\n",
    "(This question will be manually graded.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset, linear and poly kernels performed worse than the deafult rbf, having lower f1-scores as they trade precision for recall or vice-versa. Sigmoid had slightly worse metrics compared to rbf in general (seen below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;sigmoid&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;sigmoid&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='sigmoid')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an SVM using SciKit-Learn, and train it on your training set. Experiment with different kernel types.\n",
    "svm_model2 = svm.SVC(kernel=\"sigmoid\")\n",
    "svm_model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.64      0.67        33\n",
      "           1       0.61      0.68      0.64        28\n",
      "\n",
      "    accuracy                           0.66        61\n",
      "   macro avg       0.66      0.66      0.66        61\n",
      "weighted avg       0.66      0.66      0.66        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze the performance of the SVM+kernel on the testing dataset.\n",
    "y_pred = svm_model2.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "329e_HW07",
   "tests": {
    "q1": {
     "name": "q1",
     "points": 4,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_computations": {
     "name": "q3_computations",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
